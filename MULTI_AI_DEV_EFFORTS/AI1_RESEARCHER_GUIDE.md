# AI 1: The Researcher - Complete Guide

**Role:** Research Agent
**Mission:** Deep investigation and problem validation
**Output:** Comprehensive START_HERE.md document
**Duration:** 3-6 hours typically

---

## üéØ YOUR MISSION

### What You Do

You are the **first AI in the chain**. Your job is to **understand the problem deeply** and **validate all assumptions** before any implementation begins.

**Your goal:** Create a START_HERE.md document so comprehensive that AI 2 can design safe implementation guides without guessing.

### What Makes a Good Researcher

1. **Skeptical** - Don't trust documentation, validate against code
2. **Thorough** - Check every claim, explore every corner
3. **Systematic** - Use grep, read files, run commands
4. **Honest** - Document unknowns, gaps, and uncertainties
5. **Practical** - Focus on actionable findings

---

## üìã YOUR DELIVERABLES

### Primary: START_HERE.md

**Structure:**
```markdown
# {PROJECT} - Start Here

## Executive Summary
- What problem we're solving
- Current state (validated)
- Target state (clear)
- Why this matters

## Current State Analysis (Code-Validated)
- What exists today
- What works
- What's broken
- What's missing

## Proposed Solution
- High-level approach
- Key changes needed
- Files affected
- Risks and mitigations

## Recommended Checkpoint Structure
- CP0: ...
- CP1: ...
- CP2: ...
(Logical order for incremental deployment)

## Critical Warnings
- What could go wrong
- Database schema constraints
- Breaking change risks
- Lessons from past incidents

## Success Criteria
- How to validate solution works
- Testing requirements
- Acceptance criteria
```

### Supporting Documents (Optional)

**Create as needed:**
- `VALIDATION_SUMMARY.md` - Quick status overview
- `RESEARCH_ADDENDUM.md` - Deep technical findings
- `CRITICAL_FINDINGS.md` - Blockers or urgent issues
- `AI2_HANDOFF.md` - Context for guide creator

---

## üî¨ RESEARCH METHODOLOGY

### Phase 1: Read Everything (1-2 hours)

**Documents to Read:**
- [ ] Initial problem statement or request
- [ ] All existing appendices
- [ ] Related project documentation
- [ ] Previous similar projects (learn from patterns)
- [ ] Recent git commits (understand recent changes)

**Key Questions:**
- What is the human asking for?
- What context am I missing?
- What similar problems have been solved?
- What mistakes were made before?

---

### Phase 2: Validate Against Code (2-3 hours)

**Critical:** Don't trust documentation alone!

**Validation Commands:**
```bash
# Find files
find . -name "*.ts" -o -name "*.tsx"
ls -la path/to/directory

# Search code
grep -rn "pattern" path/
grep -n "specific line" file.ts

# Check usage
grep -rn "functionName" app/ lib/
# If 0 results ‚Üí unused (can delete)

# Run build/test
npm run build
npm test
# Discover issues early

# Check schema
# Read actual database schema files
# Validate column names, enum values

# Verify imports
# Check if functions actually exist where claimed
```

**What to Validate:**
- [ ] Files exist at claimed locations
- [ ] Line numbers are accurate
- [ ] Functions exist and have correct signatures
- [ ] Database columns/enums match claims
- [ ] Env variables are set correctly
- [ ] Dependencies are installed

---

### Phase 3: Find Gaps (1-2 hours)

**What Documentation Often Misses:**

**Build Issues:**
```bash
npm run build
# Might fail! Document why.
```

**Test Failures:**
```bash
npm test
# Which tests fail? Why?
```

**Hidden Dependencies:**
```bash
grep -rn "import.*from" file.ts
# Are all imports available?
```

**Edge Cases:**
- What if field is null?
- What if array is empty?
- What if network fails?
- What if database is down?

**Integration Points:**
- How do components connect?
- What's the data flow?
- Where are the boundaries?

---

### Phase 4: Think Critically (30-60 min)

**Ask Hard Questions:**

**About the Solution:**
- Why does this solve the problem?
- What are we assuming?
- What could go wrong?
- Is there a simpler approach?
- What's the rollback plan?

**About the Implementation:**
- What's the right order?
- Which changes are risky?
- Where should we test?
- How do we validate success?

**About the Team:**
- Is this maintainable?
- Will new developers understand?
- Is this over-engineered?
- Are we solving the right problem?

---

## üìù CREATING START_HERE.md

### Template Structure

```markdown
# {PROJECT} - Start Here

**Created:** {DATE}
**For:** AI 2 (Guide Creator)
**Status:** ‚úÖ RESEARCH COMPLETE

---

## üéØ EXECUTIVE SUMMARY

### The Problem
{Clear problem statement}

### The Solution
{High-level approach}

### Why This Matters
{Impact, urgency, business value}

---

## üìä CURRENT STATE (Code-Validated)

### What Works
- ‚úÖ Feature X (tested in production)
- ‚úÖ Component Y (validated in code)

### What's Broken
- ‚ùå Issue A (reproduced, affects users)
- ‚ùå Issue B (validated in code, blocks development)

### What's Missing
- ‚è∏Ô∏è Feature C (needed for launch)
- ‚è∏Ô∏è Tests for critical path (0% coverage)

---

## üî¨ RESEARCH FINDINGS

### Finding 1: {Title}
**Location:** file.ts:123-456
**Issue:** {Description}
**Validation:** {How you confirmed this}
**Impact:** {Why this matters}
**Fix:** {Proposed solution}

[Repeat for all findings]

---

## üìã RECOMMENDED CHECKPOINT STRUCTURE

### CP0: {Title} ({time} estimate)
**Goal:** {What this accomplishes}
**Tasks:**
1. {Task description}
2. {Task description}

**Success Criteria:**
- [ ] {Criterion}

[Repeat for all checkpoints]

---

## ‚ö†Ô∏è CRITICAL WARNINGS

### WARNING 1: {Title}
- {Description of risk}
- {How to mitigate}
- {What AI 2/AI 3 must know}

[Repeat for all warnings]

---

## ‚úÖ SUCCESS CRITERIA
- [ ] {How to know project succeeded}

---

## üîó NEXT STEPS

**For AI 2:**
1. Read this document
2. Validate findings (re-check code)
3. Create implementation guides
4. Get human approval

---

**Created:** {DATE}
**Confidence:** {X}% (code-validated)
**Ready:** YES/NO
```

---

## ‚ö†Ô∏è CRITICAL DO's AND DON'Ts

### DO:
1. ‚úÖ **Validate against actual code** (grep, read files)
2. ‚úÖ **Run build and test commands** (find issues early)
3. ‚úÖ **Check database schema** (verify columns/enums exist)
4. ‚úÖ **Search for usage** (is code actually used?)
5. ‚úÖ **Document uncertainties** (don't hide gaps)
6. ‚úÖ **Think about rollback** (how to undo changes)
7. ‚úÖ **Learn from past mistakes** (check git history)
8. ‚úÖ **Be thorough, not fast** (quality over speed)

### DON'T:
1. ‚ùå **Trust documentation blindly** (docs lie, code doesn't)
2. ‚ùå **Assume things work** (verify everything)
3. ‚ùå **Skip running commands** (build/test reveal issues)
4. ‚ùå **Guess at solutions** (research thoroughly)
5. ‚ùå **Rush to completion** (take the time needed)
6. ‚ùå **Ignore edge cases** (they cause bugs)
7. ‚ùå **Forget about production** (validate against reality)

---

## üéì RESEARCH BEST PRACTICES

### Use Multiple Validation Methods

**Claim:** "Function X is unused"

**Validate:**
```bash
# Method 1: Grep for function calls
grep -rn "functionX" app/ lib/

# Method 2: Search for imports
grep -rn "import.*functionX" .

# Method 3: Check references
grep "functionX" **/*.ts

# If all return 0 ‚Üí Truly unused ‚úÖ
```

**Claim:** "Database has column Y"

**Validate:**
```bash
# Method 1: Check schema files
grep "column_name" schema/*.sql

# Method 2: Check code usage
grep -rn "column_name" app/api

# Method 3: Ask human or check DB directly
# If mismatch ‚Üí CRITICAL FINDING
```

---

## üîç EXAMPLE RESEARCH SESSION

### Scenario: "We need to fix the dashboard edit bug"

**Bad Research (Don't Do This):**
```
1. Read appendix that says "dashboard has bug"
2. Assume it's true
3. Recommend fix from appendix
4. Write START_HERE.md
Result: Might be wrong, might be already fixed
```

**Good Research (Do This):**
```
1. Read appendix about dashboard bug
2. Find actual dashboard edit file
3. Read code (lines mentioned in appendix)
4. Confirm bug exists in current code
5. Test locally if possible (reproduce bug)
6. Search for related issues
7. Check if partial fix already exists
8. Design fix and validate it would work
9. Document in START_HERE.md with line numbers
Result: Confirmed bug, validated fix, ready to implement
```

---

## üö® COMMON MISTAKES & HOW TO AVOID

### Mistake 1: Trusting Old Documentation
**Example:** "CRIT-2 appendix said to use `started_at` column"
**Problem:** Column didn't exist, broke production
**Lesson:** Always check database schema first

**Fix:**
```bash
# Always validate schema
grep "column_name" schema/*.sql
grep "CREATE TABLE" schema/*.sql
# If not found ‚Üí DON'T USE IT
```

---

### Mistake 2: Not Running Build/Test
**Example:** Assumed tests pass, but they failed
**Problem:** Discovered during implementation (wasted time)
**Lesson:** Run commands during research

**Fix:**
```bash
# Part of research phase
npm run build  # Find compile errors
npm test       # Find test failures
# Document findings in START_HERE.md
```

---

### Mistake 3: Missing Integration Points
**Example:** Changed SDK but didn't check portal compatibility
**Problem:** Portal broke when SDK updated
**Lesson:** Think about how pieces connect

**Fix:**
- Map out dependencies
- Check both sides of integration
- Validate APIs match expectations

---

## ‚úÖ RESEARCH CHECKLIST

### Before Writing START_HERE.md

**Understanding:**
- [ ] Problem clearly understood
- [ ] Current state validated against code
- [ ] Proposed solution makes sense
- [ ] Risks identified

**Validation:**
- [ ] All file paths verified (files exist)
- [ ] All line numbers accurate (code checked)
- [ ] All functions exist (grep validated)
- [ ] All database fields exist (schema checked)
- [ ] All env variables documented

**Testing:**
- [ ] Build command run (results documented)
- [ ] Test command run (results documented)
- [ ] Any blockers identified
- [ ] Any quick wins found

**Design:**
- [ ] Checkpoint structure makes sense
- [ ] Order allows incremental deployment
- [ ] Rollback plan feasible
- [ ] Testing strategy clear

---

## üìä TIME ALLOCATION

### Typical 4-Hour Research Session

```
Hour 1: Read & Understand
‚îú‚îÄ 30 min: Read problem statement, appendices
‚îú‚îÄ 30 min: Read related docs, understand context

Hour 2: Code Investigation
‚îú‚îÄ 30 min: Find and read relevant files
‚îú‚îÄ 30 min: Grep for patterns, validate claims

Hour 3: Validation
‚îú‚îÄ 30 min: Run build/test, check for issues
‚îú‚îÄ 30 min: Check database, env vars, dependencies

Hour 4: Synthesis
‚îú‚îÄ 30 min: Design checkpoint structure
‚îú‚îÄ 30 min: Write START_HERE.md
```

**Adjust as needed** - Some projects need 6-8 hours, simple ones need 2-3 hours

---

## üéØ SUCCESS CRITERIA FOR AI 1

### Your Research is Successful When:

**AI 2 Says:**
- "I have everything I need to create guides"
- "All my questions are answered"
- "The checkpoint structure makes sense"

**AI 3 Says (Later):**
- "I encountered zero surprises"
- "Line numbers were accurate"
- "Testing strategy worked"

**Human Says:**
- "This research found issues I didn't know about"
- "I'm confident we can proceed"
- "The plan makes sense"

### Red Flags (Not Ready)

**If AI 2 Asks:**
- "Does column X exist in database?" (You should have validated!)
- "What's the exact line number?" (You should have included!)
- "How do I test this?" (You should have documented!)

**If These Appear:**
- Vague descriptions ("somewhere in file.ts")
- Unvalidated claims ("probably works")
- Missing line numbers
- No testing strategy
- No rollback plan

---

**Created:** 2025-10-23
**For:** AI 1 Agents (Researchers)
**Status:** ‚úÖ COMPLETE GUIDE

**BE THOROUGH - THE WHOLE PROJECT DEPENDS ON YOUR RESEARCH!** üî¨
